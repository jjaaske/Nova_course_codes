{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 3 - Splitting the data into training (70%) and validation (30%)\n"],"metadata":{"id":"vcYhX5JPvnUQ"}},{"cell_type":"code","source":["path_to_tiles=\"/content/drive/MyDrive/NOVA_course_deep_learning/data/annotated_data/train\"\n","\n","# define split for training and validation\n","\n","split_train= 0.7\n","split_val=1-split_train"],"metadata":{"id":"ESxfoDbRtkVj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1 Loading libraries and mounting Google Drive"],"metadata":{"id":"IOOTsKg9tf-D"}},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","\n","# mount google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"KQ9Ofi8kt8AI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.2 Creating train and validation directories and subdivide each into \"images\" and \"labels\" sub-directories"],"metadata":{"id":"6hLdXNOguHeA"}},{"cell_type":"code","source":["train_dir = os.path.join(path_to_tiles, \"train\")\n","os.makedirs(train_dir, exist_ok=True)            # creates new directory for training data\n","val_dir = os.path.join(path_to_tiles, \"val\")\n","os.makedirs(val_dir, exist_ok=True)              # creates new directory for validation data\n","val_img_dir = os.path.join(path_to_tiles, \"val\",\"images\")\n","os.makedirs(val_img_dir, exist_ok=True)          # creates new directory for training data\n","train_img_dir = os.path.join(path_to_tiles, \"train\",\"images\")\n","os.makedirs(train_img_dir, exist_ok=True)        # creates new directory for training data\n","val_ann_dir = os.path.join(path_to_tiles, \"val\",\"labels\")\n","os.makedirs(val_ann_dir, exist_ok=True)          # creates new directory for training data\n","train_ann_dir = os.path.join(path_to_tiles, \"train\",\"labels\")\n","os.makedirs(train_ann_dir, exist_ok=True)        # creates new directory for training data\n"],"metadata":{"id":"EO4_BRQauMrb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.3 Randomly sampling tiles"],"metadata":{"id":"RpooLhCauWx_"}},{"cell_type":"code","source":["# Get a list of all the .txt files in the data directory\n","\n","txt_files = [f for f in os.listdir(path_to_tiles) if f.endswith(\".txt\")]\n","img_files = [f for f in os.listdir(path_to_tiles) if f.endswith(\".tif\")]"],"metadata":{"id":"sAH2eQwTF-fQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove .txt files that have no image\n","\n","txt_files_with_tif = []\n","for txt_file in txt_files:\n","\n","    # get the base name of the text file\n","\n","    txt_base_name = os.path.basename(txt_file)\n","\n","    # replace the file extension with .tif to get the corresponding tif file name\n","\n","    img_file = os.path.join(os.path.dirname(txt_file), os.path.splitext(txt_base_name)[0] + '.tif')\n","    img_file=path_to_tiles+\"/\"+img_file\n","\n","    #print(\"txt: \"+txt_file)\n","    #print(\"tif: \"+img_file)\n","    # check if the tif file exists\n","\n","    if os.path.exists(img_file):\n","\n","      #print(\"path to image \" + img_file + \" does not exist!\")\n","\n","      txt_files_with_tif.append(txt_file)\n","\n"],"metadata":{"id":"l6_I5DQEDd0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["txt_files=txt_files_with_tif\n","\n","# Shuffle the list of text files\n","\n","random.shuffle(txt_files)\n","\n","# Calculate the number of files for the train and validation sets\n","\n","train_size = int(0.7 * len(txt_files))\n","val_size = len(txt_files) - train_size"],"metadata":{"id":"2Olsju2esPOl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.4 Moving the text annotation files and respective images to the train and validation directories"],"metadata":{"id":"DwIl8JDcyBey"}},{"cell_type":"code","source":["# iterate through each annotated .txt file\n","\n","for i, txt_file in enumerate(txt_files):\n","    if i < train_size:\n","        dest_dir = train_dir\n","    else:\n","        dest_dir = val_dir\n","\n","\n","    if os.path.exists(path_to_tiles+\"/\"+txt_file):\n","      src_file = os.path.join(path_to_tiles, txt_file)\n","      src_img = os.path.join(path_to_tiles, os.path.splitext(txt_file)[0]+\".tif\")\n","      if os.path.exists(src_img):\n","        dest_file = os.path.join(dest_dir,\"labels\", txt_file)\n","        dest_img = os.path.join(dest_dir,\"images\", os.path.splitext(txt_file)[0]+\".tif\")\n","\n","        #print(\"copying files\")\n","\n","        shutil.move(src_file, dest_file)\n","        shutil.move(src_img, dest_img)"],"metadata":{"id":"6sGgm68syA51"},"execution_count":null,"outputs":[]}]}